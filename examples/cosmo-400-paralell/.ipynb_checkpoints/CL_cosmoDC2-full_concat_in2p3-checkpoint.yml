---

id: Firecrown
# Python modules that are imported to find
# stage classes.  Any stages imported in these
# modules are automatically detected and their names can
# be used below
modules: clpipeline

# The launcher to use
# These are defined in ceci/sites
launcher:
    name: mini
    interval: 0.5

# launcher:
#   name: parsl
#   # max_threads only referenced for local sites
#   #log: parsl_log.txt

# launcher:
#     name: cwl
#     launcher: cwltool
#     dir: ./test/cwl

site:
    name: local
    max_threads: 4
  # max_threads: 4
  # container: joezuntz/txpipe
  # volume:  $PWD:/opt/txpipe



#site:
#    name: nersc-interactive
#    # Put the log for the overall pipeline infrastructure in this file:
#    pipeline_log: log.txt

# site:
#     name: nersc-batch
#     cpu_type: haswell
#     queue: debug
#     max_jobs: 2
#     account: m1727
#     walltime: "00:30:00"
#     setup: /global/projecta/projectdirs/lsst/groups/WL/users/zuntz/setup-cori



# The list of stages to run and the number of processors
# to use for each.
stages:
    - name: FirecrownPipeline
      module_name: clpipeline.firecrown_pipeline
      nprocess: 1

# Definitions of where to find inputs for the overall pipeline.
# Any input required by a pipeline stage that is not generated by
# a previous stage must be defined here.  They are listed by tag.
inputs:
    clusters_sacc_file_cov: ./outputs/clusters_sacc_file_cov.sacc

# Overall configuration file 
config: ./cosmodc2_config_in2p3.yml

# If all the outputs for a stage already exist then do not re-run that stage
resume: False

# Put all the output files in this directory:
output_dir: ./outputs

# Put the logs from the individual stages in this directory:
log_dir: ./logs

---

id: TXPipe
#this step depends on where you run
#for CCin2p3
site:
    name: local
    max_threads: 60
#site:
#    name: cori-batch
#    image: ghcr.io/lsstdesc/txpipe-dev
#all the following steps should not depend on where you run
launcher:
    name: mini
    interval: 0.5
modules: >
    txpipe
    rail.estimation.algos.bpz_lite
python_paths: []
stages:
  - name: CLIngestRedmapper # This will Ingest the cluster catalog from GCR
    nprocess: 30
  - name: TXShearCalibration # This has to take the galaxy catalog with shear and calibrate it.
  - name: FlowCreator       # Simulate a spectroscopic population. Prepares the model. This and the next two stages are responsible for generating a spec-z sample for the BPZ algorithm. THis will compute a pdf(z) for the galaxies to be used to compute the shear profile
    nprocess: 1
    aliases:
        output: ideal_specz_catalog
        model: flow
  - name: GridSelection             # Simulate a spectroscopic sample from the model defined above. 
    nprocess: 1
    aliases:
        input: ideal_specz_catalog
        output: specz_catalog_pq
  - name: TXParquetToHDF            # Convert to HDF5
    nprocess: 1
    aliases:
        input: specz_catalog_pq
        output: spectroscopic_catalog
  - name: TXSourceSelectorMetadetect
    nprocess: 60
  - name: BPZliteInformer
    nprocess: 1
    aliases:
        input: spectroscopic_catalog
        model: photoz_model
  - name: BPZliteEstimator
    nprocess: 60
    aliases:
        model: photoz_model
        input: shear_catalog
        output: source_photoz_pdfs
  - name: CLClusterBinningRedshiftRichness
    nprocess: 1
  - name: CLClusterShearCatalogs
    nprocess: 60   #>1 does not work with mpi
  - name: CLClusterEnsembleProfiles
    nprocess: 10
  - name: CLClusterSACC
    nprocess: 1
    aliases:
        cluster_profiles: cluster_profiles
#    - name: CLClusterDataVector
#      nprocess: 1
output_dir: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/outputs-full/
# Put the logs from the individual stages in this directory:
log_dir: ./logs

# Put the logs from the individual stages in this directory:
config: ./cosmodc2_config_in2p3.yml
inputs:
    # See README for paths to download these files
    shear_catalog: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/full/shear_catalog.hdf5
    #photometry_catalog:  /sps/lsst/users/mricci/TXPipe_data/data_link/cosmodc2/20deg2/photometry_catalog.hdf5
    fiducial_cosmology: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/fiducial_cosmology.yml
    calibration_table: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/20deg2/sample_cosmodc2_w10year_errors.dat
    spectroscopic_catalog: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/20deg2/spectroscopic_catalog.hdf5
    cluster_catalog: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/full/cluster_catalog.hdf5
    #shear_tomography_catalog: ./data/example/outputs_metadetect/shear_tomography_catalog.hdf5
    #source_photoz_pdfs: ./data/example/inputs/photoz_pdfs.hdf5
resume: true
pipeline_log: ./logs/log_full.txt

---
id: TJPCov
# Python modules that are imported to find
# stage classes.  Any stages imported in these
# modules are automatically detected and their names can
# be used below
modules: clpipeline

# The launcher to use
# These are defined in ceci/sites
launcher:
    name: mini
    interval: 0.5
# launcher:
#   name: parsl
#   # max_threads only referenced for local sites
#   #log: parsl_log.txt

# launcher:
#     name: cwl
#     launcher: cwltool
#     dir: ./test/cwl

site:
    name: local
    max_threads: 4
  # max_threads: 4
  # container: joezuntz/txpipe
  # volume:  $PWD:/opt/txpipe



#site:
#    name: nersc-interactive
#    # Put the log for the overall pipeline infrastructure in this file:
#    pipeline_log: log.txt

# site:
#     name: nersc-batch
#     cpu_type: haswell
#     queue: debug
#     max_jobs: 2
#     account: m1727
#     walltime: "00:30:00"
#     setup: /global/projecta/projectdirs/lsst/groups/WL/users/zuntz/setup-cori



# The list of stages to run and the number of processors
# to use for each.
stages:
    - name: TJPCovPipeline
      module_name: clpipeline.tjpcov_pipeline
      nprocess: 1

# Definitions of where to find inputs for the overall pipeline.
# Any input required by a pipeline stage that is not generated by
# a previous stage must be defined here.  They are listed by tag.
inputs:
    clusters_sacc_file: /sps/lsst/groups/clusters/cl_pipeline_project/TXPipe_data/cosmodc2/outputs-20deg2-CL/cluster_sacc_catalog.sacc

# Overall configuration file 
config: ./cosmodc2_config_in2p3.yml


# If all the outputs for a stage already exist then do not re-run that stage
resume: False

# Put all the output files in this directory:
output_dir: ./outputs


# Put the logs from the individual stages in this directory:
log_dir: ./logs

---

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce72d1d-8281-4bbe-87cd-ce47bcf23c83",
   "metadata": {},
   "source": [
    "# Firecrown Tutorial\n",
    "## 1. Introduction\n",
    "Firecrown is a framework to run likelihoods. It is a software built to have as input code predictions and make a connection with `cosmosis`, a sampler code, such that we are able to run an MCMC. There are several types of likelihood options built in in firecrown and generally we just have to provide the likelihood python function and smome configuration files. In this tutorial I will focus on what is needed to run the cluster examples, how the prediction module works, how to structure a python likelihood for firecrown and how to obtain the theory prediction in a python file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59e401-7934-453b-8917-cd72406b6996",
   "metadata": {},
   "source": [
    "## How to run and which files are needed\n",
    "To run firecrown, we need 3 different files. A likelihood.py file (cluster_redshift_richness_deltasigma.py), a cosmosis configuration file (for instance https://github.com/LSSTDESC/firecrown/blob/master/examples/cluster_number_counts/cluster_counts_mean_mass_redshift_richness_shear.ini), and another cosmosis file with the cosmological parameters and the desired parameters to be varied in the mcmc (for example https://github.com/LSSTDESC/firecrown/blob/master/examples/cluster_number_counts/cluster_richness_values_deltasigma.ini)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848ff40-f7c9-4f4f-8167-46c4e15fc412",
   "metadata": {},
   "source": [
    "## Likelihood file\n",
    "The likelihood file has to have the method `build_likelihood`, and it has to return a firecrown likelihood and modeling tools. FOr instance, in the above likelihood cited file, we have\n",
    "\n",
    "\n",
    "```\n",
    "def build_likelihood(\n",
    "    build_parameters: NamedParameters,\n",
    ") -> tuple[Likelihood, ModelingTools]:\n",
    "    \"\"\"Builds the likelihood for Firecrown.\"\"\"\n",
    "    # Pull params for the likelihood from build_parameters\n",
    "    average_on = ClusterProperty.NONE\n",
    "    if build_parameters.get_bool(\"use_cluster_counts\", True):\n",
    "        average_on |= ClusterProperty.COUNTS\n",
    "    if build_parameters.get_bool(\"use_mean_log_mass\", True):\n",
    "        average_on |= ClusterProperty.MASS\n",
    "    if build_parameters.get_bool(\"use_mean_deltasigma\", True):\n",
    "        average_on |= ClusterProperty.DELTASIGMA\n",
    "\n",
    "    survey_name = \"numcosmo_simulated_redshift_richness_deltasigma\"\n",
    "    likelihood = ConstGaussian(\n",
    "        [\n",
    "            BinnedClusterNumberCounts(\n",
    "                average_on, survey_name, MurataBinnedSpecZRecipe()\n",
    "            ),\n",
    "            BinnedClusterDeltaSigma(\n",
    "                average_on, survey_name, MurataBinnedSpecZDeltaSigmaRecipe()\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Read in sacc data\n",
    "    sacc_file_nm = \"cluster_redshift_richness_deltasigma_sacc_data.fits\"\n",
    "    sacc_path = os.path.expanduser(\n",
    "        os.path.expandvars(\"${FIRECROWN_DIR}/examples/cluster_number_counts/\")\n",
    "    )\n",
    "    sacc_data = sacc.Sacc.load_fits(os.path.join(sacc_path, sacc_file_nm))\n",
    "    likelihood.read(sacc_data)\n",
    "    cluster_abundance = get_cluster_abundance()\n",
    "    cluster_deltasigma = get_cluster_deltasigma()\n",
    "    modeling_tools = ModelingTools(\n",
    "        cluster_abundance=cluster_abundance, cluster_deltasigma=cluster_deltasigma\n",
    "    )\n",
    "\n",
    "    return likelihood, modeling_tools\n",
    "```\n",
    "\n",
    "In this, we can see that the likelihood function needs to have a couple of things. It needs to read the data to be used, in a SACC file. Firecrown has some helpers to interpret the data. And the likelihood function must have statistics that compute the theoretical prediction. We can see that if we go on `BinnedClusterNumberCounts`, this is defined for clusters and has the theoretical prediction functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ce815-5c03-4032-a883-609a937c60ed",
   "metadata": {},
   "source": [
    "## Cosmosis files\n",
    "\n",
    "IN the cosmosis files, is where we defined the sampler to be used, the configrations fo the sampler, which likelihood file we will use. It is basically to set all the paths and recomended files in place. It is a configuration file.  Let us look at the `examples/cluster_number_counts/cluster_counts_mean_mass_redshift_richness_shear.ini`\n",
    "\n",
    "```\n",
    "[runtime]\n",
    "sampler = test\n",
    "resume = T\n",
    "root = ${PWD}\n",
    "```\n",
    "The test sampler runs just one iteration. It is useful to see if everything is set correctly. When running an mcmc , on must change the sampler option.\n",
    "\n",
    "In the pipeline section is where we set the path to the parameters file, in this case  `cluster_richness_values_deltasigma.ini` and the modules we want to use\n",
    "```\n",
    "[pipeline]\n",
    "modules = consistency camb firecrown_likelihood\n",
    "values = ${FIRECROWN_DIR}/examples/cluster_number_counts/cluster_richness_values_deltasigma.ini\n",
    "likelihoods = firecrown\n",
    "quiet = T\n",
    "debug = T\n",
    "timing = T\n",
    "```\n",
    "Finaly, in the firecrown likelihood, we will set parameters that will be use in our likelihood file above. You can see that these parameters were acced with build_parameters in the likelihood file. THe `sampling_parameters_sections` is what is defined in the parameters file cited above. The cosmological parameters are already expected by the file, so if your statistics has some unique parameters to be varied, you have to specify in a new sectino and put this section here.\n",
    "```\n",
    "[firecrown_likelihood]\n",
    ";; Fix this to use an environment variable to find the files.\n",
    ";; Set FIRECROWN_DIR to the base of the firecrown installation (or build, if you haven't\n",
    ";; installed it)\n",
    "file = ${FIRECROWN_DIR}/firecrown/connector/cosmosis/likelihood.py\n",
    "likelihood_source = ${FIRECROWN_DIR}/examples/cluster_number_counts/cluster_redshift_richness_deltasigma.py\n",
    "sampling_parameters_sections = firecrown_number_counts\n",
    "use_cluster_counts = True\n",
    "use_mean_log_mass = False\n",
    "use_mean_deltasigma = True\n",
    "```\n",
    "\n",
    "```\n",
    "[test]\n",
    "fatal_errors = T\n",
    "save_dir = output_counts_mean_mass\n",
    "\n",
    "[metropolis]\n",
    "samples = 1000\n",
    "nsteps = 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b05f2e-8b32-493e-a398-12767492440d",
   "metadata": {},
   "source": [
    "## The parameters configuration file\n",
    "In the parameter configuration file is where we set our cosmological parameters plus the parameters that need to be varied in our code. Let us take a look at `cluster_richness_values_deltasigma.ini`\n",
    "\n",
    "```\n",
    "; Parameters and data in CosmoSIS are organized into sections\n",
    "; so we can easily see what they mean.\n",
    "; There is only one section in this case, called cosmological_parameters\n",
    "[cosmological_parameters]\n",
    "\n",
    "; These are the only cosmological parameters being varied.\n",
    "omega_c = 0.1552 0.22 0.3552\n",
    "# We are choosing to use a flat prior in sigma_8.\n",
    "# To choose a float prior in A_s, remove the specification\n",
    "# of a prior for sigma_8 and replace it with the\n",
    "# desired range for A_s\n",
    "sigma_8 = 0.7 0.800 0.9\n",
    "; The following parameters are set, but not varied.\n",
    ";\n",
    "omega_k = 0.0\n",
    "omega_b = 0.0448\n",
    "tau = 0.08\n",
    "n_s = 0.963\n",
    "h0 = 0.71\n",
    "w = -1.0\n",
    "wa = 0.0\n",
    "\n",
    "[firecrown_number_counts]\n",
    "; These are the firecrown likelihood parameters.\n",
    "; These parameters are used to set the richness-mass\n",
    "; proxy relation using the data from cluster number counts.\n",
    ";\n",
    "; The following parameters can be fixed in the same way as the above\n",
    "; cosmological parameters if needed.\n",
    "mu_p0 = 3.19\n",
    "mu_p1 = 0.868\n",
    "mu_p2 = -0.3\n",
    "sigma_p0 = 0.33\n",
    "sigma_p1 = -0.034 \n",
    "sigma_p2 = 0.0\n",
    "cluster_conc = 4.\n",
    "```\n",
    "\n",
    "The cosmological parameters section is always present, while for this specific example, we define also the firecrown number coutns section with the parameters we want to vary or set in our statiscs. A single value means that this will be the parameter set for this parameter. 3 values mean that the value will be varied between the left and right and start in the midle, with flat priors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d057d139-a009-4860-97f7-b1edfe7afc7e",
   "metadata": {},
   "source": [
    "##  how to run firecrown clusters\n",
    "\n",
    "To run, after all the files are set, one must use the cosmosis command in the terminal with the configuration file\n",
    "```\n",
    "cosmosis cluster_counts_mean_mass_redshift_richness_shear.ini\n",
    "```\n",
    "NOte that this should be done in the terminal only for the test sampler. If one wants to run the chain, this should be done inside a slurm job "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b08573-2095-4c27-879b-61f5457ff419",
   "metadata": {},
   "source": [
    "## CLuster Modeling in firecrown\n",
    "Now we will discuss a bit of the modeling theoretical prediction code that is present in firecrown. So the modeling code consists on some files:\n",
    "- abundance and cluster delta sigma: These two files define the cluster abundance object and the predictions for the tangential shear and cluster abundance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722280c-d76b-457f-b442-53017834a081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21291be7-0912-4f67-93d4-5c0ca4bf90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "how does the code for cluster works, import functions from separate modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9c3a2-de0e-4c38-9d6c-151d138bdff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "How does it work with the recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd66ba2-a10c-4e58-901e-951bd93a4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "define a prediction function here and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b19919-238c-48cb-8c71-6a31088ddc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts_deltasigma_prediction_from_sacc(path, survey_nm, pivot_mass, pivot_redshift, mu_p0, mu_p1, mu_p2, sigma_p0, sigma_p1, sigma_p2, mass_parameter=False):\n",
    "    s_read = sacc.Sacc.load_fits(path)\n",
    "\n",
    "    \n",
    "    hmf = ccl.halos.MassFuncDespali16()\n",
    "    min_mass, max_mass = 13., 16.\n",
    "    min_z, max_z = 0.2, 0.8\n",
    "    cluster_deltasigma = ClusterDeltaSigma((min_mass, max_mass), (min_z, max_z), hmf)\n",
    "    cluster_abundance = ClusterAbundance((min_mass, max_mass), (min_z, max_z), hmf)\n",
    "    cosmo_ccl = ccl.Cosmology(\n",
    "    Omega_c=0.2052,\n",
    "    Omega_b=0.0448,\n",
    "    h=0.71,\n",
    "    n_s=0.963,\n",
    "    sigma8=0.8,\n",
    "    Omega_k=0.0,\n",
    "    Neff=3.044,\n",
    "    m_nu=0.0,\n",
    "    w0=-1.0,\n",
    "    wa=0.0,\n",
    "    T_CMB=2.7255\n",
    "    )\n",
    "    cluster_abundance.update_ingredients(cosmo_ccl)\n",
    "    cluster_deltasigma.update_ingredients(cosmo_ccl)\n",
    "    \n",
    "    modeling_tools = ModelingTools(cluster_abundance = cluster_abundance, cluster_deltasigma=cluster_deltasigma)\n",
    "    mds = MDS()\n",
    "    mds.mass_distribution.pivot_mass = np.log(10**pivot_mass)\n",
    "    mds.mass_distribution.pivot_redshift = pivot_redshift\n",
    "    mds.mass_distribution.log1p_pivot_redshift = np.log1p(pivot_redshift)\n",
    "    mds.mass_distribution.mu_p0 = mu_p0\n",
    "    mds.mass_distribution.mu_p1 = mu_p1\n",
    "    mds.mass_distribution.mu_p2 = mu_p2\n",
    "    mds.mass_distribution.sigma_p0 = sigma_p0\n",
    "    mds.mass_distribution.sigma_p1 = sigma_p1\n",
    "    mds.mass_distribution.sigma_p2 = sigma_p2\n",
    "    \n",
    "    mds.mass_distribution_unb.pivot_mass = np.log(10**pivot_mass)\n",
    "    mds.mass_distribution_unb.pivot_redshift = pivot_redshift\n",
    "    mds.mass_distribution_unb.log1p_pivot_redshift = np.log1p(pivot_redshift)\n",
    "    mds.mass_distribution_unb.mu_p0 = mu_p0\n",
    "    mds.mass_distribution_unb.mu_p1 = mu_p1\n",
    "    mds.mass_distribution_unb.mu_p2 = mu_p2\n",
    "    mds.mass_distribution_unb.sigma_p0 = sigma_p0\n",
    "    mds.mass_distribution_unb.sigma_p1 = sigma_p1\n",
    "    mds.mass_distribution_unb.sigma_p2 = sigma_p2\n",
    "\n",
    "    mds.purity_distribution.ap_nc = 1.98\n",
    "    mds.purity_distribution.bp_nc = 0.812\n",
    "    mds.purity_distribution.ap_rc = 2.2183\n",
    "    mds.purity_distribution.bp_rc = -0.6592\n",
    "    \n",
    "    mds.completeness_distribution.ac_nc = 1.1321\n",
    "    mds.completeness_distribution.bc_nc = 0.7751\n",
    "    mds.completeness_distribution.ac_mc = 13.31\n",
    "    mds.completeness_distribution.bc_mc = 0.2025\n",
    "\n",
    "    average_on = ClusterProperty.DELTASIGMA\n",
    "    if mass_parameter:\n",
    "        average_on |= ClusterProperty.MASS\n",
    "    bin_cl_theory = BinnedClusterDeltaSigma(average_on, survey_nm, mds)\n",
    "    bin_cl_theory.read(s_read)\n",
    "    cluster_abundance.update_ingredients(cosmo_ccl)\n",
    "\n",
    "    prediction = bin_cl_theory._compute_theory_vector(modeling_tools)\n",
    "    data = bin_cl_theory.data_vector\n",
    "    return data, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25922d-04ae-4edf-b862-e66f50ac710c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de05625-4c92-4278-8f09-cd5aa43227d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2991ae-2cff-4057-b367-cdd33ea379b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706ca8a-61a2-4c08-b0dd-316e2fbf30e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c18ff6-46f6-47cf-acbe-d011852350db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5661d3-5d23-4941-b097-1c52092d1c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077a364-7220-464a-85ca-d3fe4e05ba11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186fda4-f325-4f93-b6d2-8c9075e5424a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853b871-f76c-428a-bcec-43e1e2ab1e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8d6e5-8bd4-47f5-8b0b-a5a208d97b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Firecrown_clp",
   "language": "python",
   "name": "firecrown_clp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
